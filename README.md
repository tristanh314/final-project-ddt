# Final Project Proposal: Portland Housing Cost Estimator

## How much is too much?
Buying a house is a huge investment in time, money, and energy. Consumers needs and desires for their property vary widely, as do their budgets. But even if one can find a home that fits ones needs, how can one know they are getting a good deal? We attempt a programmatic approach to this problem. Our final product will be an interactive application that allows a user to input desired specifications for a Portland home such as number of bedrooms, number of bathrooms, square footage, lot acreage, year constructed, county, city, zip code, and local schools. Using a machine learning model, a price will be generated based on the input criteria. The goal will be to return a price that the user can then use a baseline when evaluating individual listings.

## Methodology
Data from individual listings will be scraped from [Portland MLS Search](https://www.portlandmlsdirect.com/). This data will then be combined and stored in a SQLite database. Information from this database will then be used to train a machine learning model. First, data preprocessing will transform categorical data into numerical and/or one-hot-encoded data as necessary. A random forest will be used to determine which factors have the strongest influence on price. Based on these results, those factors will be used to create a model that can be used to predict the price of a house. A deep learning neural network using the standard "relu" and "softmax" activation functions will be the first step. Other kinds of model may be attempted after doing additional research as the project progresses. After a satisfactory model has been trained and tested, it will be used in a Flask app that will take user input criteria and make a prediction of price for a house fitting that using the saved model. Should time allow, additional models will be developed for locales besides Portland. Also, time permitting, we may attempt to introduce periodic updates to the database by performing new web scrapings to retrain the model periodically with the most recently avaialable data.

### Tristan Holmes, Daniel Love, and Devin Milligan
